% !TEX root =  master.tex
\chapter{Praktischer Teil}

\section{Umsetzung}

Eine der wohl wichtigsten Entscheidungen bei der Implementation
eines Machine Learning Modells ist die Auswahl der Rohdaten.
Nach intensiver Recherche wurde sich für einen Datensatz
entschieden welcher Informationen über alle Bundesliga-Spiele
seit der Saison 2005/2006 enthält. Dieser Rohdatensatz besitzt
65+ Features. Während des Preprocessings wurde die Anzahl der Features durch
das Löschen unvollständiger oder für das Modell unnötiger Features, zum Beispiel die
Odds verschiedener Wettanbieter, deutlich reduziert. Diese Features wurden dann
harmonisiert und mit einer Korrelationsmatrix auf ihre Aussagekraft geprüft.
Da diese nach der ersten Featureauswahl noch nicht zufriedenstellend war
wurden weitere Features berechnet und in den Datensatz aufgenommen. So wurden
beispielsweise die aktuelle Form der Mannschaften (Elo) sowie Angriffs- und
Verteidigungswerte errechnet. Um die Aussagekraft weiter zu erhöhen wurden außerdem
Features eingeführt, die einen direktern Vergleich der Mannschaften ermöglichen.
Diese Features sind zum Beispiel Differenzen der Elo und Angriffs- sowie Verteidigungswerte
oder die Anzahl der Punkte und Tore, die eine Mannschaft während der letzten Spiele erzielt hat.

(Hier Grafik von Datensatz)

Dadurch, dass die Zielvariablen bereits im Datensatz  vorliegen
handelt es sich um ein Supervised Learning-Problem. Dieses wurde
wie im Theorieteil erwähnt mit drei verschiedenen Methoden angegangen.
Dem Ensemble Learning, einem Neural Network sowie einem mathematischen Ansatz.

\section{Ergebnisse}

Angefangen beim Ensemble Learning kann man verschiedene Accuracys
je Algorithmus erkennen (Grafik zeigen). Hierbei sind die Logistic
Regression und Linear Discriminant Analysis am Besten. Das
Stacking Modell welches die anderen Modelle vereint schneidet
auch gut ab. Alle drei liegen bei einer Accuracy von etwas unter
50 Prozent.

Bei Betrachtung des Neural Networks fällt auf, dass die Accuracy
schon nach wenigen Epochen auf etwas unter 50 Prozent konvergiert
(Grafik). Nach einer Random Parameter Search konnte diese auf 53
Prozent angehoben werden. Zuletzt haben wir mit der Poisson-
Verteilung des mathematischen Ansatzes auch eine Accuracy von
etwa 50 Prozent erreicht (Grafik).

\section{Use Case Validierung durch simulierte Wetten}

Um zu testen, wie gut das Modell unter Realbedingungen funktioniert
wurden im Verlauf der Saison 2021/22 Wetten simuliert. Für die
Simulation wurden die Predictions des Modells mit den Predictions von
vier verschiedenen Wettanbietern verglichen. Um die Predictions der
Wettanbieter zu erhalten wurde zuerst der Durchschnitt der Odds der
Wettanbieter für jedes Ereignis (Sieg Heimteam, Unentschieden, Sieg Auswärtsteam)
ermittelt. Dieser Durchschnitt wurde dann in eine Prozentzahl umgewandelt
und nach dem Maximum gefiltert um eine Prediction für jeden Spieltag zu erhalten.
Um auf die Predictions zu setzen mussten diese einen gewissen Schwellwert (XX\% Sicherheit) überschreiten.
Bei Überschreitung des Schwellwerts wurde je nach Höhe der \% Zahl ein bestimmter Betrag gewettet.
(Grafik wie viel ab welcher \% Zahl gewettet wird)

Auf die gesamte Saison 2021/22 betrachtet ergibt sich folgende Grafik.
(Grafik mit den Wetten)
Es lässt sich erkennen, dass das Modell am Ende der Saison zwar mehr Gewinn gemacht
hat, die Wettanbieter aber im Laufe der Saion besser performen. Auf die Bedeutung der Grafik
in Bezug auf den Business Use Case wird im Fazit genauer eingegangen.
